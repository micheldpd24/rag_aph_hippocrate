{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ae6a817",
   "metadata": {},
   "source": [
    "# RAG sur les Aphorismes d'Hippocrate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e1d93c",
   "metadata": {},
   "source": [
    "## 0. üìò Introduction\n",
    "\n",
    "Ce notebook propose une approche m√©thodologique pour extraire, nettoyer et structurer les *Aphorismes* d'Hippocrate √† partir d'une √©dition ancienne num√©ris√©e au format PDF. L‚Äôobjectif final est de pr√©parer ces textes en vue de leur int√©gration dans un syst√®me de **RAG** (*Retrieval-Augmented Generation*), permettant ainsi d‚Äôen faciliter l‚Äôanalyse et l‚Äôinterpr√©tation par des mod√®les de langage moderne.\n",
    "\n",
    "### üìÑ Source du document\n",
    "- **Titre** : *Aphorismes d'Hippocrate*, traduits en fran√ßais par √âmile Littr√©  \n",
    "- **√âditeur** : J.-B. Bailli√®re  \n",
    "- **Lieu** : Paris  \n",
    "- **Ann√©e** : 1844  \n",
    "- **Format num√©rique** : PDF (num√©risation d‚Äôun ouvrage ancien)\n",
    "\n",
    "### üîç Champ d‚Äô√©tude\n",
    "Seule la **traduction fran√ßaise** des *Aphorismes* nous int√©resse ici. Elle est reprise dans le document PDF entre les **pages 96 et 260**, et constitue la base du corpus √† traiter dans ce projet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b911341e",
   "metadata": {},
   "source": [
    "Positionnment √† la racine du r√©pertoire du projet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9701d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/micheldpd/Projects/rag_aph_hippocrate'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd\n",
    "import os\n",
    "os.chdir(\"..\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eaf1c1b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 1. Configuration de l'environnement\n",
    "\n",
    "Commen√ßons par importer les biblioth√®ques n√©cessaires et configurer le logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2fc1833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "import logging\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Configuration du logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger('aphorism_extractor')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f12ce08",
   "metadata": {},
   "source": [
    "## 2. T√©l√©chargement des \"Aphorismes d'Hippocrate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8a815b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier t√©l√©charg√© et sauvegard√© en : km/aphorismes_hippocrate.pdf\n"
     ]
    }
   ],
   "source": [
    "# URL source du fichier PDF\n",
    "url = \"https://archive.org/download/aphorismesdhippo00hipp/aphorismesdhippo00hipp.pdf\"\n",
    "\n",
    "# Chemin de destination local\n",
    "output_path = \"km/aphorismes_hippocrate.pdf\"\n",
    "\n",
    "# Cr√©er le dossier km/ s'il n'existe pas\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "# T√©l√©chargement du fichier\n",
    "response = requests.get(url, stream=True)\n",
    "response.raise_for_status()  # V√©rifie qu'il n'y a pas d'erreur (ex: 404)\n",
    "\n",
    "# √âcriture dans le fichier\n",
    "with open(output_path, \"wb\") as f:\n",
    "    for chunk in response.iter_content(chunk_size=8192):\n",
    "        f.write(chunk)\n",
    "\n",
    "print(f\"Fichier t√©l√©charg√© et sauvegard√© en : {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1773b323",
   "metadata": {},
   "source": [
    "## 3. Extraction des textes du PDF\n",
    "\n",
    "Le premier d√©fi consiste √† extraire correctement le texte du PDF, qui pr√©sente des caract√©ristiques propres aux livres anciens num√©ris√©s: mots coup√©s en fin de ligne, structure irr√©guli√®re, etc.\n",
    "\n",
    "### 3.1 Nettoyage des tirets en fin de ligne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3147828",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_hyphens(text: str) -> str:\n",
    "    \"\"\"Supprime les '-' en fin de ligne et fusionne les mots coup√©s.\"\"\"\n",
    "    lines = text.splitlines()\n",
    "    cleaned_lines = []\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        line = lines[i].rstrip()\n",
    "        if line.endswith('-'):\n",
    "            # Enlever le '-', prendre le mot sans tiret\n",
    "            word_part = line[:-1]\n",
    "            if i + 1 < len(lines):\n",
    "                next_line = lines[i + 1].lstrip()\n",
    "                # Si la ligne suivante commence par une lettre minuscule, c'est probablement la suite\n",
    "                if next_line and next_line[0].islower():\n",
    "                    line = word_part + next_line\n",
    "                    i += 1  # sauter la prochaine ligne\n",
    "                else:\n",
    "                    line = word_part + next_line\n",
    "                    i += 1\n",
    "            else:\n",
    "                line = word_part\n",
    "        cleaned_lines.append(line)\n",
    "        i += 1\n",
    "    return \"\\n\".join(cleaned_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb2c855",
   "metadata": {},
   "source": [
    "### 3.2 Correction des formats de num√©rotation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a880936f",
   "metadata": {},
   "source": [
    "Un Aphorisme, dans le document source analys√© commence par un nombre √† deux chiffres maximum suivi d'un point ou d'une virgule. En effet, lors de l'extraction de text du pdf certain points sont transform√©s en virgule. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaee80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_comma_after_number(line_text: str) -> str:\n",
    "    \"\"\"Remplace les virgules apr√®s un num√©ro par un point (pour normaliser la num√©rotation).\"\"\"\n",
    "    return re.sub(r'^(\\d{1,2}),', r'\\1.', line_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25746792",
   "metadata": {},
   "source": [
    "### 3.3 Extraction des paragraphes par page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f4cf83",
   "metadata": {},
   "source": [
    "Nous retenons uniquement le texte principal des Aphorismes , en omettant les notes de bas de page qui peuvent parfois repr√©senter un volume significatif. Afin de distinguer le corps du texte des notes, nous segmentons chaque page en paragraphes √† l‚Äôaide de MyMuPDF , en nous appuyant notamment sur les espaces entre lignes (interlignes) pour identifier les s√©parations entre √©l√©ments textuels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4af579c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_until_nth_paragraph(page: fitz.Page, n: int = 2, line_gap_threshold: float = 1.8):\n",
    "    \"\"\"\n",
    "    Extrait le texte jusqu'au n-i√®me paragraphe d'une page.\n",
    "    D√©tecte les paragraphes selon l'espacement vertical entre les lignes.\n",
    "    \n",
    "    Args:\n",
    "        page: Page PyMuPDF\n",
    "        n: Nombre de paragraphes √† extraire\n",
    "        line_gap_threshold: Facteur multiplicateur pour l'espacement qui d√©finit un nouveau paragraphe\n",
    "    \n",
    "    Returns:\n",
    "        Texte extrait jusqu'au n-√®me paragraphe\n",
    "    \"\"\"\n",
    "    text_dict = page.get_text(\"dict\")\n",
    "    blocks = text_dict[\"blocks\"]\n",
    "    lines = []\n",
    "    last_y = None\n",
    "    avg_line_height = 0\n",
    "    paragraph_count = 1\n",
    "    start_extraction = False  # On attend la premi√®re ligne valide (>=15 caract√®res)\n",
    "    \n",
    "    for block in blocks:\n",
    "        if \"lines\" in block:\n",
    "            for line in block[\"lines\"]:\n",
    "                y = line[\"bbox\"][1]\n",
    "                line_text = \" \".join(span[\"text\"] for span in line[\"spans\"]).strip()\n",
    "\n",
    "                # === FILTRE : ignorer les lignes vides ou trop courtes (< 2)\n",
    "                if not line_text or len(line_text) < 2:\n",
    "                    continue\n",
    "\n",
    "                # === ATTENTE DE LA PREMI√àRE LIGNE LONGUE (>=15) ===\n",
    "                if not start_extraction:\n",
    "                    if len(line_text) >= 15:\n",
    "                        start_extraction = True  # C'est ici qu'on commence\n",
    "                        line_text = replace_comma_after_number(line_text)\n",
    "                        lines.append(line_text)\n",
    "                else:\n",
    "                    # === EXTRACTION NORMALE APR√àS LE D√âMARRAGE ===\n",
    "                    line_text = replace_comma_after_number(line_text)\n",
    "                    if last_y is not None:\n",
    "                        gap = y - last_y\n",
    "                        if gap > line_gap_threshold * avg_line_height:\n",
    "                            paragraph_count += 1\n",
    "                            if paragraph_count > n:\n",
    "                                return \"\\n\".join(lines)\n",
    "                            lines.append(\"\\n\" + line_text)\n",
    "                        else:\n",
    "                            lines.append(line_text)\n",
    "                    else:\n",
    "                        lines.append(line_text)\n",
    "                # Mise √† jour pour la prochaine ligne\n",
    "                last_y = y\n",
    "                avg_line_height = line[\"bbox\"][3] - line[\"bbox\"][1]\n",
    "                \n",
    "    return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc90dc0",
   "metadata": {},
   "source": [
    "### 3.4 Traitement du PDF complet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7498c174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_part2(pdf_path: str, start_page: int = 96, end_page: int = 260):\n",
    "    \"\"\"\n",
    "    Traite une section du PDF contenant les aphorismes.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path: Chemin vers le fichier PDF\n",
    "        start_page: Num√©ro de la premi√®re page √† traiter\n",
    "        end_page: Num√©ro de la derni√®re page √† traiter\n",
    "        \n",
    "    Returns:\n",
    "        Dictionnaire {num√©ro_page: texte_extrait}\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    results = {}\n",
    "    \n",
    "    for page_num in range(start_page, end_page): \n",
    "        # V√©rifier si la page est paire (num√©ro de page impair en 0-index√©)\n",
    "        if (page_num) % 2 == 0:  # On ne traite que les pages paires (contenant le texte principal)\n",
    "            page = doc.load_page(page_num)\n",
    "\n",
    "            # D√©terminer la valeur de n selon les r√®gles sp√©cifiques au livre\n",
    "            current_page_number = page_num\n",
    "            if current_page_number in [100]:\n",
    "                n_val = 3\n",
    "            elif current_page_number in [110, 128, 146, 176, 190]:\n",
    "                n_val = 4\n",
    "            else:\n",
    "                n_val = 2\n",
    "                \n",
    "            # Extraction du texte\n",
    "            text = extract_until_nth_paragraph(page, n=n_val)\n",
    "            text = remove_hyphens(text)  # Supprimer les tirets\n",
    "            results[current_page_number] = text\n",
    "            \n",
    "    doc.close()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ca9483",
   "metadata": {},
   "source": [
    "## 4. Extraction des aphorismes\n",
    "\n",
    "Une fois le texte extrait des pages, nous devons identifier et extraire chaque aphorisme num√©rot√©.\n",
    "\n",
    "### 4.1 Extraction des aphorismes d'une page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ee5c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_aphorisms(page_data: dict, all_texts: dict) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Extrait tous les aphorismes √† partir d'un texte extrait de page.\n",
    "    G√®re les cas o√π un aphorisme est coup√© sur une autre page (page x+2).\n",
    "\n",
    "    Args:\n",
    "        page_data (dict): {'page_num', 'section', 'text'}\n",
    "        all_texts (dict): {page_num: text}, pour chercher les suites\n",
    "\n",
    "    Returns:\n",
    "        list[dict]: Liste d'aphorismes trouv√©s\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    current_page = page_data[\"page_num\"]\n",
    "    lines = [line.strip() for line in page_data[\"text\"].splitlines() if line.strip()]\n",
    "    \n",
    "    logger.info(f\"Traitement de la page {current_page} avec {len(lines)} lignes\")\n",
    "    \n",
    "    # On commence √† partir de la 2√®me ligne\n",
    "    start_idx = min(1, len(lines) - 1)\n",
    "    \n",
    "    # Traitement des aphorismes sur la page courante\n",
    "    aphorisms_current_page = _process_current_page_aphorisms(lines, start_idx, current_page, page_data[\"section\"])\n",
    "    \n",
    "    # Traitement des aphorismes qui continuent sur la page x+2\n",
    "    final_results = _handle_cross_page_aphorisms(aphorisms_current_page, current_page, all_texts, page_data[\"section\"])\n",
    "    \n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe452884",
   "metadata": {},
   "source": [
    "### 4.2 Traitement des aphorismes sur une page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf17bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process_current_page_aphorisms(lines: list, start_idx: int, current_page: int, first_line: str) -> list:\n",
    "    \"\"\"\n",
    "    Traite les aphorismes sur la page courante.\n",
    "    \n",
    "    Args:\n",
    "        lines (list): Liste des lignes de texte\n",
    "        start_idx (int): Index de d√©part pour le traitement\n",
    "        current_page (int): Num√©ro de la page courante\n",
    "        first_line (str): Premi√®re ligne de la page pour r√©f√©rence\n",
    "        \n",
    "    Returns:\n",
    "        list: Liste contenant les aphorismes complets et le dernier incomplet s'il existe\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    i = start_idx\n",
    "    current_number = None\n",
    "    current_text = \"\"\n",
    "    \n",
    "    while i < len(lines):\n",
    "        line = lines[i]\n",
    "        \n",
    "        # D√©tection d'un nouveau num√©ro d'aphorisme\n",
    "        match = re.match(r\"^(\\d{1,2})[.,]\\s*(.*)\", line)\n",
    "        if match:\n",
    "            if current_number is not None:\n",
    "                # Finir l'aphorisme pr√©c√©dent\n",
    "                results.append({\n",
    "                    \"page\": current_page,\n",
    "                    \"section\": first_line,\n",
    "                    \"aphorism_number\": current_number,\n",
    "                    \"text\": current_text.strip(),\n",
    "                    \"status\": \"complete\"  # Par d√©faut, on suppose qu'il est complet\n",
    "                })\n",
    "                logger.debug(f\"Aphorisme {current_number} termin√© sur la page {current_page}\")\n",
    "                current_text = \"\"\n",
    "            \n",
    "            # Nouveau num√©ro d√©tect√©\n",
    "            current_number = match.group(1).zfill(2)\n",
    "            current_text = match.group(2).strip() + \" \"\n",
    "            logger.debug(f\"Nouvel aphorisme {current_number} d√©tect√© sur la page {current_page}\")\n",
    "        elif current_number is not None:\n",
    "            # Continuation du texte\n",
    "            current_text += line.strip() + \" \"\n",
    "        \n",
    "        i += 1\n",
    "    \n",
    "    # Ajouter le dernier aphorisme s'il existe\n",
    "    if current_number and current_text.strip():\n",
    "        results.append({\n",
    "            \"page\": current_page,\n",
    "            \"section\": first_line,\n",
    "            \"aphorism_number\": current_number,\n",
    "            \"text\": current_text.strip(),\n",
    "            \"status\": \"potentially_incomplete\"  # Il pourrait continuer sur une autre page\n",
    "        })\n",
    "        logger.debug(f\"Aphorisme {current_number} potentiellement incomplet √† la fin de la page {current_page}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbbc447",
   "metadata": {},
   "source": [
    "### 4.3 Gestion des aphorismes coup√©s entre pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6200221e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _handle_cross_page_aphorisms(aphorisms: list, current_page: int, all_texts: dict, first_line: str) -> list:\n",
    "    \"\"\"\n",
    "    Traite les aphorismes qui pourraient continuer sur la page x+2.\n",
    "    \n",
    "    Args:\n",
    "        aphorisms (list): Liste des aphorismes de la page courante\n",
    "        current_page (int): Num√©ro de la page courante\n",
    "        all_texts (dict): Dictionnaire de tous les textes par page\n",
    "        first_line (str): Premi√®re ligne de la page pour r√©f√©rence\n",
    "        \n",
    "    Returns:\n",
    "        list: Liste mise √† jour des aphorismes\n",
    "    \"\"\"\n",
    "    if not aphorisms:\n",
    "        return []\n",
    "    \n",
    "    # Tous les aphorismes sauf le dernier sont complets\n",
    "    complete_aphorisms = aphorisms[:-1]\n",
    "    \n",
    "    # V√©rifier si le dernier aphorisme continue sur la page x+2\n",
    "    last_aphorism = aphorisms[-1]\n",
    "    if last_aphorism[\"status\"] == \"potentially_incomplete\":\n",
    "        next_page = current_page + 2\n",
    "        \n",
    "        if next_page in all_texts:\n",
    "            logger.info(f\"V√©rification de la continuation de l'aphorisme {last_aphorism['aphorism_number']} sur la page {next_page}\")\n",
    "            \n",
    "            next_text = all_texts[next_page]\n",
    "            next_lines = [line.strip() for line in next_text.splitlines() if line.strip()]\n",
    "            \n",
    "            # D√©terminer si cet aphorisme continue sur la page suivante\n",
    "            continuation_text = _find_aphorism_continuation(next_lines[1:], last_aphorism[\"aphorism_number\"])\n",
    "            \n",
    "            if continuation_text:\n",
    "                # Mettre √† jour le texte de l'aphorisme avec sa continuation\n",
    "                last_aphorism[\"text\"] += \" \" + continuation_text\n",
    "                last_aphorism[\"status\"] = \"cross_page_complete\"\n",
    "                logger.info(f\"Aphorisme {last_aphorism['aphorism_number']} compl√©t√© √† travers les pages {current_page} et {next_page}\")\n",
    "            else:\n",
    "                last_aphorism[\"status\"] = \"complete\"\n",
    "        else:\n",
    "            logger.warning(f\"Page suivante {next_page} non disponible pour v√©rifier la continuation de l'aphorisme {last_aphorism['aphorism_number']}\")\n",
    "            last_aphorism[\"status\"] = \"complete\"  # On le consid√®re complet par d√©faut\n",
    "    \n",
    "    # Nettoyer les statuts avant de retourner les r√©sultats\n",
    "    for aphorism in complete_aphorisms + [last_aphorism]:\n",
    "        aphorism.pop(\"status\", None)\n",
    "    \n",
    "    return complete_aphorisms + [last_aphorism]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ce0ec1",
   "metadata": {},
   "source": [
    "### 4.4 Recherche de la continuation d'un aphorisme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d619460e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_aphorism_continuation(next_lines: list, current_number: str) -> str:\n",
    "    \"\"\"\n",
    "    Cherche la continuation d'un aphorisme sur la page suivante.\n",
    "    \n",
    "    Args:\n",
    "        next_lines (list): Liste des lignes sur la page suivante\n",
    "        current_number (str): Num√©ro de l'aphorisme courant\n",
    "        \n",
    "    Returns:\n",
    "        str: Texte de continuation ou cha√Æne vide si aucune continuation trouv√©e\n",
    "    \"\"\"\n",
    "    continuation_text = \"\"\n",
    "    \n",
    "    # On commence √† la deuxi√®me ligne pour ignorer potentiellement l'en-t√™te\n",
    "    j = 1\n",
    "    while j < len(next_lines):\n",
    "        line = next_lines[j]\n",
    "        logger.debug(f\"Examen de la ligne pour continuation: {line}\")\n",
    "        \n",
    "        # D√©tection d'un nouveau num√©ro sur la page suivante\n",
    "        match = re.match(r\"^(\\d{1,2})\\.\\s*(.*)\", line)\n",
    "        if match:\n",
    "            # Un nouvel aphorisme commence, donc fin de la continuation\n",
    "            break\n",
    "        else:\n",
    "            # Ajout du texte √† la continuation\n",
    "            continuation_text += \" \" + line.strip()\n",
    "        j += 1\n",
    "    \n",
    "    return continuation_text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3513d2",
   "metadata": {},
   "source": [
    "### 4.5 Fonction utilitaire: Normalisation des num√©ros de section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edbcb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_sections(ligne):\n",
    "    # Dictionnaire de correspondance\n",
    "    remplacements = {\n",
    "        'PR': 'SECTION.1',\n",
    "        'DEU': 'SECTION.2',\n",
    "        'TRO': 'SECTION.3',\n",
    "        'QUA': 'SECTION.4',\n",
    "        'CIN': 'SECTION.5',\n",
    "        'SIX': 'SECTION.6',\n",
    "        'SEP': 'SECTION.7',\n",
    "        'BEP': 'SECTION.7'\n",
    "    }\n",
    "\n",
    "    # Nettoyer la ligne pour faciliter la recherche\n",
    "    ligne_nettoyee = ligne.strip()\n",
    "\n",
    "    # V√©rifier si l'un des mots-cl√©s est pr√©sent\n",
    "    for mot, section in remplacements.items():\n",
    "        if mot in ligne_nettoyee:\n",
    "            return section\n",
    "\n",
    "    # Si aucun mot-cl√© trouv√©, retourner la ligne originale\n",
    "    return ligne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deaed4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_sections(\"ccc PREMIERE SECTION vvv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac108f51",
   "metadata": {},
   "source": [
    "### 4.6 Extraction des aphorismes √† travers toutes les pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014ac8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_aphorisms_across_pages(extracted_texts: dict) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Extrait tous les aphorismes √† travers toutes les pages trait√©es.\n",
    "    \n",
    "    Args:\n",
    "        extracted_texts (dict): Dictionnaire {page_num: texte} des textes extraits\n",
    "        \n",
    "    Returns:\n",
    "        list: Liste de tous les aphorismes extraits\n",
    "    \"\"\"\n",
    "    all_aphorisms = []\n",
    "    sorted_pages = sorted(extracted_texts.keys())\n",
    "    \n",
    "    logger.info(f\"D√©but du traitement de {len(sorted_pages)} pages\")\n",
    "    \n",
    "    for page_num in sorted_pages:\n",
    "        text = extracted_texts[page_num]\n",
    "        \n",
    "        # V√©rification que le texte contient au moins une ligne\n",
    "        if not text.strip():\n",
    "            logger.warning(f\"Page {page_num} vide ou sans contenu valide, ignor√©e\")\n",
    "            continue\n",
    "            \n",
    "        lines = text.splitlines()\n",
    "        if not lines:\n",
    "            logger.warning(f\"Page {page_num} sans lignes valides, ignor√©e\")\n",
    "            continue\n",
    "            \n",
    "        first_line = normalize_sections(lines[0].strip())\n",
    "\n",
    "        page_data = {\n",
    "            \"page_num\": page_num,\n",
    "            \"section\": first_line,\n",
    "            \"text\": text\n",
    "        }\n",
    "\n",
    "        logger.info(f\"Traitement de la page {page_data['page_num']} (original: {page_num})\")\n",
    "        aphorisms = extract_aphorisms(page_data, extracted_texts)\n",
    "        \n",
    "        if aphorisms:\n",
    "            logger.info(f\"Page {page_data['page_num']}: {len(aphorisms)} aphorismes extraits\")\n",
    "            all_aphorisms.extend(aphorisms)\n",
    "        else:\n",
    "            logger.info(f\"Page {page_data['page_num']}: aucun aphorisme trouv√©\")\n",
    "\n",
    "    logger.info(f\"Extraction termin√©e: {len(all_aphorisms)} aphorismes au total\")\n",
    "\n",
    "    # Enregistrement des r√©sultats dans un fichier JSON\n",
    "    with open(\"data/aphorisms_extracted.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(all_aphorisms, f, ensure_ascii=False, indent=4)\n",
    "    logger.info(\"Aphorismes extraits enregistr√©s dans 'data/aphorisms_extracted.json'\")\n",
    "    return all_aphorisms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3695f8",
   "metadata": {},
   "source": [
    "### 4.7 Affichage des aphorismes pour v√©rification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97428258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_aphorisms(aphorisms: list) -> None:\n",
    "    \"\"\"\n",
    "    Affiche les aphorismes extraits pour v√©rification.\n",
    "    \n",
    "    Args:\n",
    "        aphorisms (list): Liste des aphorismes √† afficher\n",
    "    \"\"\"\n",
    "    for aph in aphorisms:\n",
    "        print(f\" {aph['section']} | Aphorisme {aph['aphorism_number']} | Page {aph['page']} | longueur_aph: {len(aph['text'])}\")\n",
    "        print(f\"{aph['text']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9550ea",
   "metadata": {},
   "source": [
    "## 5. Pipeline complet\n",
    "\n",
    "Utilisons maintenant toutes ces fonctions dans un pipeline complet pour extraire et corriger les aphorismes d'Hippocrate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d9dad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin du fichier PDF\n",
    "pdf_path = \"km/aphorismes_hippocrate.pdf\"\n",
    "    \n",
    "# 1. Extraction des textes\n",
    "print(\"√âtape 1: Extraction des textes du PDF...\")\n",
    "extracted_texts = process_test_part2(pdf_path, start_page=96, end_page=260)\n",
    "print(f\"  - {len(extracted_texts)} pages trait√©es\")\n",
    "    \n",
    "# 2. Extraction des aphorismes\n",
    "print(\"\\n√âtape 2: Extraction des aphorismes...\")\n",
    "all_aphorisms = extract_aphorisms_across_pages(extracted_texts)\n",
    "print(f\"{len(all_aphorisms)} aphorismes extraits\")\n",
    "    \n",
    "# 3. Affichage d'un √©chantillon pour v√©rification\n",
    "print(\"\\n√âtape 3: V√©rification d'un √©chantillon...\")\n",
    "sample_size = min(5, len(all_aphorisms))\n",
    "display_aphorisms(all_aphorisms[:sample_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b598ef",
   "metadata": {},
   "source": [
    "## 6. Analyse des r√©sultats\n",
    "\n",
    "Une fois les aphorismes extraits et corrig√©s, nous pouvons effectuer quelques analyses pour valider la qualit√© des donn√©es."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247a6c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_results(json_file=\"data/aphorisms_extracted.json\"):\n",
    "    \"\"\"\n",
    "    Analyse les r√©sultats extraits et corrig√©s des aphorismes.  \n",
    "    \"\"\"\n",
    "    # Chargement des donn√©es corrig√©es\n",
    "    with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        aphorismes = json.load(f)\n",
    "    \n",
    "    # Statistiques de base\n",
    "    nb_aphorismes = len(aphorismes)\n",
    "    longueurs = [len(a[\"text\"]) for a in aphorismes]\n",
    "    longueur_moyenne = sum(longueurs) / nb_aphorismes if nb_aphorismes > 0 else 0\n",
    "    longueur_min = min(longueurs) if longueurs else 0\n",
    "    longueur_max = max(longueurs) if longueurs else 0\n",
    "    \n",
    "    print(f\"Nombre total d'aphorismes: {nb_aphorismes}\")\n",
    "    print(f\"Longueur moyenne: {longueur_moyenne:.1f} caract√®res\")\n",
    "    print(f\"Longueur min: {longueur_min} caract√®res\")\n",
    "    print(f\"Longueur max: {longueur_max} caract√®res\")\n",
    "    \n",
    "    # Distribution des longueurs\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(longueurs, bins=20)\n",
    "    plt.title(\"Distribution de la longueur des aphorismes\")\n",
    "    plt.xlabel(\"Nombre de caract√®res\")\n",
    "    plt.ylabel(\"Nombre d'aphorismes\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show\n",
    "    # plt.savefig(\"distribution_longueurs.png\")\n",
    "    # plt.close()\n",
    "\n",
    "\n",
    "analyze_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f23dc50",
   "metadata": {},
   "source": [
    "## 8. Pr√©paration pour le syst√®me RAG\n",
    "\n",
    "Pour int√©grer ces aphorismes dans un syst√®me RAG, il est essentiel de les formatter correctement afin de faciliter leur traitement. Cela implique notamment de segmenter les textes trop longs (d√©passant 500 caract√®res) ainsi que ceux de moins de 500 caract√®res, en pr√©vision des √©tapes d‚Äôembedding, de construction de l‚Äôindex et d‚Äôincorporation dans le contexte lors de l‚Äôappel au mod√®le de langage (LLM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb0e9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_document(aphorism, part_suffix=\"\", text_slice=slice(None)):\n",
    "    \"\"\"\n",
    "    Helper to create a document entry.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"id\": f\"s{aphorism['section'][-1]}.aph_{aphorism['aphorism_number']}{part_suffix}.p{aphorism['page']}\",\n",
    "        \"text\": aphorism[\"text\"][text_slice],\n",
    "        \"metadata\": {\n",
    "            \"source\": \"Hippocrate, Aphorismes\",\n",
    "            \"section\": aphorism[\"section\"],\n",
    "            \"aphorism_number\": f\"{aphorism['aphorism_number']}{part_suffix}\",\n",
    "            \"page\": aphorism[\"page\"],\n",
    "            \"category\": \"medical_ancient_text\"\n",
    "        }\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43174e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_for_rag(\n",
    "    input_path=\"data/aphorisms_extracted.json\",\n",
    "    output_path=\"data/hippocrate_rag_data.json\",\n",
    "    short_limit=450,\n",
    "    medium_limit=800\n",
    "):\n",
    "    with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        aphorismes = json.load(f)\n",
    "\n",
    "    rag_documents = []\n",
    "\n",
    "    for aph in aphorismes:\n",
    "        text = aph[\"text\"]\n",
    "        length = len(text)\n",
    "\n",
    "        if length <= short_limit:\n",
    "            # Single short aphorism\n",
    "            rag_documents.append(create_document(aph))\n",
    "\n",
    "        elif length <= medium_limit:\n",
    "            # Split into two parts\n",
    "            mid = length // 2\n",
    "            rag_documents.append(create_document(aph, \"_1\", slice(mid)))\n",
    "            rag_documents.append(create_document(aph, \"_2\", slice(mid - 30, None)))\n",
    "\n",
    "        else:\n",
    "            # Split into three parts\n",
    "            ter = length // 3\n",
    "            rag_documents.append(create_document(aph, \"_1\", slice(ter)))\n",
    "            rag_documents.append(create_document(aph, \"_2\", slice(ter - 30, 2 * ter)))\n",
    "            rag_documents.append(create_document(aph, \"_3\", slice(2 * ter - 30, None)))\n",
    "\n",
    "    # Add introduction document\n",
    "    intro_doc = {\n",
    "        \"id\": \"hippocrate_intro\",\n",
    "        \"text\": (\n",
    "            \"Les Aphorismes d'Hippocrate sont une collection de maximes m√©dicales attribu√©es \"\n",
    "            \"√† Hippocrate de Cos (environ 460-370 av. J.-C.), consid√©r√© comme le p√®re de la \"\n",
    "            \"m√©decine occidentale. Ces courts √©nonc√©s r√©sument les observations cliniques et \"\n",
    "            \"les principes th√©rapeutiques de l'√©poque, formant une base importante de la \"\n",
    "            \"pens√©e m√©dicale pendant des si√®cles.\"\n",
    "        ),\n",
    "        \"metadata\": {\n",
    "            \"source\": \"Aphorismes d'Hippocrate*, traduits en fran√ßais par √âmile Littr√© , 1844\",\n",
    "            \"category\": \"context\"\n",
    "        }\n",
    "    }\n",
    "    rag_documents.append(intro_doc)\n",
    "\n",
    "    # Save to file\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(rag_documents, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(f\"{len(rag_documents)} documents pr√©par√©s pour le syst√®me RAG\")\n",
    "\n",
    "# Run the function\n",
    "prepare_for_rag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9929c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_results(\"data/hippocrate_rag_data.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da664ca6",
   "metadata": {},
   "source": [
    "## 9. Conclusion et perspectives\n",
    "\n",
    "Ce notebook a pr√©sent√© une m√©thode compl√®te pour:\n",
    "1. Extraire des textes d'un PDF ancien avec une structure complexe\n",
    "2. Identifier et structurer les aphorismes d'Hippocrate\n",
    "3. Pr√©parer les donn√©es pour un syst√®me RAG\n",
    "\n",
    "### Points forts de l'approche:\n",
    "\n",
    "- Gestion des sp√©cificit√©s des livres anciens (mots coup√©s, structure non standard)\n",
    "- Traitement des aphorismes √† cheval sur plusieurs pages\n",
    "- Pipeline modulaire et extensible\n",
    "\n",
    "### Pistes d'am√©lioration:\n",
    "- Utilisation d'un LLM pour la correction du texte tout en pr√©servant le style\n",
    "- Sauvegarde progressive des donn√©es pendant le traitement\n",
    "- Ajouter une √©tape de validation manuelle pour les corrections propos√©es par le LLM\n",
    "- Incorporer des m√©tadonn√©es suppl√©mentaires (cat√©gorisation th√©matique des aphorismes)\n",
    "- Optimiser les requ√™tes au LLM pour r√©duire les temps d'attente\n",
    "- Ajouter un syst√®me de d√©tection des erreurs d'OCR plus sophistiqu√©\n",
    "- √âtendre la m√©thode √† d'autres textes m√©dicaux historiques\n",
    "\n",
    "### Applications possibles:\n",
    "\n",
    "- Assistant m√©dical historique pour les chercheurs en histoire de la m√©decine\n",
    "- Outil p√©dagogique pour les √©tudiants en m√©decine\n",
    "- Interface de recherche s√©mantique pour explorer l'h√©ritage d'Hippocrate\n",
    "- Base pour la comparaison avec d'autres textes m√©dicaux anciens\n",
    "\n",
    "Ce notebook fournit un cadre m√©thodologique qui peut √™tre adapt√© √† d'autres textes anciens num√©ris√©s, contribuant ainsi √† la pr√©servation et √† l'accessibilit√© du patrimoine m√©dical historique."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
