
# ğŸ›ï¸ Assistant Hippocratique : RAG basÃ© sur les Aphorismes d'Hippocrate

> â€œJe jure par Apollon mÃ©decin, par AsclÃ©pios, Hygie et PanacÃ©eâ€¦â€  
> â€” Serment dâ€™Hippocrate

## ğŸ“Œ Ã€ propos

Ce projet est une **application web interactive utilisant un systÃ¨me RAG (Retrieval-Augmented Generation)** basÃ© sur les cÃ©lÃ¨bres **Aphorismes d'Hippocrate**, destinÃ©e Ã  explorer et se familiariser avec ces textes anciens fondements antique Ã  grace Ã  l'intelligence artificielle.

Il permet Ã  tout utilisateur de poser des questions liÃ©es aux aphorismes, et reÃ§oit une rÃ©ponse contextuelle construite Ã  partir des textes originaux enrichis par un modÃ¨le de langage (ex: Mistral).

---

## ğŸ” Objectifs du projet

- âœ¨ Explorer une base historique de textes hippocratiques anciens
- ğŸ§  Utiliser le RAG pour amÃ©liorer l'apprentissage interactif
- ğŸ“š Mettre en avant les principes hippocratiques dans un format numÃ©rique moderne
- ğŸ§‘â€âš•ï¸ Inspirer une approche pÃ©dagogique de la redÃ©couverte des textes de la mÃ©dÃ©cine ancienne

---

## âš–ï¸ Enjeux pÃ©dagogiques et Ã©ducatifs

### ğŸ§‘â€ğŸ« 1. Vulgarisation des textes fondamentaux de la mÃ©dÃ©cine hippocratique

- Permet aux utilisateur de d'explorer et de se familiariser avec les fondements historiques de la mÃ©dÃ©cine.
- Favorise lâ€™apprentissage critique grÃ¢ce Ã  l'ancrage dans des textes fondateurs.
- Ouvre Ã  une rÃ©flexion sur lâ€™Ã©volution de la pensÃ©e mÃ©dicale depuis lâ€™AntiquitÃ©.

### ğŸ“š 2. Apprentissage interactif

- Introduit une mÃ©thode pÃ©dagogique active oÃ¹ lâ€™utilisateur pose des questions et reÃ§oit des rÃ©ponses contextualisÃ©es.
- Permet de travailler la compÃ©tence "recherche documentaire + synthÃ¨se" via un assistant IA.
- Encourage l'autonomie dans l'apprentissage avec suivi personnalisÃ©.

### ğŸ§  3. RÃ©fÃ©rentiel SÃ©mantique MÃ©dical Ancien

- Exploration dâ€™un corpus ancien par des techniques modernes de traitement du langage naturel.
- PremiÃ¨re Ã©tape vers la crÃ©ation de rÃ©fÃ©rentiels mÃ©dicaux anciens accessibles par NLP.
- Application potentielle Ã  dâ€™autres textes mÃ©dicaux classiques (Galien, Avicenne, etc.)

### 4. Exemple pratique d'implÃ©mentation d'un RAG
- Exemple pÃ©dagogique de conception et de mise en oeuvre d'un RAG basÃ© sur un document pdf.

---

## ğŸ¤– Fonctionnement technique

### ğŸ§  1. Base de connaissances

Les **Aphorismes d'Hippocrate** sont :
    - Extraits du pdf livre ancien "Aphorismes d'Hippocrate traduit en franÃ§ais, .. par E. LittrÃ©, Paris, Chez J.B. BaillÃ¨re, 1844. Source : 
    - DÃ©coupÃ© et stockÃ©s dans un fichier JSON (`data/hippocrate_rag_data.json`) 
    - et intÃ©grÃ©s dans un index FAISS aprÃ¨s encodage sÃ©mantique avec un modÃ¨le de type **Sentence-BERT (camembert-large)**.

### ğŸ” 2. Recherche vectorielle

Ã€ chaque question posÃ©e :
1. La requÃªte est encodÃ©e en vecteur avec le mÃªme modÃ¨le.
2. Une recherche par plus proches voisins est effectuÃ©e dans lâ€™index FAISS.
3. Les passages les plus pertinents sont rÃ©cupÃ©rÃ©s.

### ğŸ§¾ 3. GÃ©nÃ©ration de rÃ©ponse

La rÃ©ponse est gÃ©nÃ©rÃ©e par un **modÃ¨le LLM open-source (Mistral)** via **Ollama**, qui reformule la rÃ©ponse en franÃ§ais, sur la base des extraits trouvÃ©s.

---

## ğŸ§° Technologies utilisÃ©es

| Technologie | Utilisation |
|------------|-------------|
| Flask      | Backend API web |
| Bootstrap 5.3 | Interface responsive |
| Sentence-BERT | Encodage sÃ©mantique |
| FAISS      | Indexation vectorielle |
| Mistral (Ollama) | GÃ©nÃ©ration de rÃ©ponses |
| Docker     | DÃ©ploiement portable |
| Bleach     | SÃ©curisation HTML |

---

## ğŸ“¦ PrÃ©requis

- Python 3.9+
- Docker (optionnel mais recommandÃ©)
- AccÃ¨s Ã  Ollama (ou autre serveur LLM compatible)

---

## ğŸš€ DÃ©marrage rapide

### Avec Docker Compose (recommandÃ©)

```bash
docker-compose up --build
```

Lâ€™application sera accessible Ã  lâ€™adresse : [http://localhost:5000](http://localhost:5000)

```bash
docker exec -it my-ollama ollama run mistral
```

### Ou en mode dÃ©veloppement local

prÃ©parer l'environnement virtual
```bash
python -m venv .venv
```
Sous mac os / linux : 
```bash
source .venv/bin/activate
```
Sous windows CMD :
```bash
.venv\Scripts\activate
```
Installer les librairies nÃ©cessaires pour le projet
```bash
pip install -r requirements.txt
```

Assurer vous que ollama est installÃ© et dÃ©marrer ollama
```bash
ollama serve
```

DÃ©marrer le modele LLM qui sera appelÃ© par le RAG (mistral dans ce projet)
```bash
ollama run mistral
```

lancer l'assitant IA hippocratique
```bash
python app.py
```

AccÃ©der Ã  l'interface de l"'assistant IA Hippocratique Ã  l'adresse
[http://localhost:5000](http://localhost:5000)

---

## ğŸ—‚ Structure du projet

```
.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ aphorisms_extracted.json    # Corpus des aphorismes
â”‚   â”œâ”€â”€ hippocrates_questions.json  # Questions prÃ©dÃ©finies (pour UI)
â”‚   â””â”€â”€ hippocrate_rag_data.json    # Corpus des aphorismes
â”œâ”€â”€ models/
â”‚   â””â”€â”€ config_schema.py            # SchÃ©ma de configuration Pydantic pour le RAG
â”œâ”€â”€ prepare_corpus/
â”‚   â””â”€â”€ process_pdf.ipynb           # Notebook qui prÃ©pare le Corpus du RAG Ã  partir du document pdf sur les Aphorismes d'Hippocrate
â”œâ”€â”€ rag/
â”‚   â””â”€â”€ hippocrate.py               # Construction de l'index FAISS, fonction de recherche dans l'index, fonction d'appel du LLM
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html                  # Template Jinja
â”œâ”€â”€ app.py                          # Point d'entrÃ©e Flask
â”œâ”€â”€ config_loader.py                # Loader of rag configuration yaml file
â”œâ”€â”€ Dockerfile                      # Docker
â”œâ”€â”€ docker-compose.yml              # Orchestration
â”œâ”€â”€ rag_config.yaml                 # Configuration file of the RAG (Flask application, embedding model, llm, data path, security, ...)
â””â”€â”€ requirements.txt                # DÃ©pendances Python
```

---

## PrÃ©paration du corpus pour le RAG hippocratique: prepare_corpus/process_pdf.ipynb

Dans le cadre de la mise en place dâ€™un systÃ¨me de **RAG (Retrieval-Augmented Generation)** centrÃ© sur les *Aphorismes dâ€™Hippocrate*, il est essentiel de prÃ©parer un **corpus textuel structurÃ©, propre et adaptÃ©** aux exigences techniques des modÃ¨les de recherche sÃ©mantique et de gÃ©nÃ©ration.

### ğŸ“„ Source du corpus
Les donnÃ©es proviennent dâ€™une Ã©dition ancienne numÃ©risÃ©e :
- **Titre** : *Aphorismes d'Hippocrate*, traduits par Ã‰mile LittrÃ©  
- **Format numÃ©rique** : PDF issu de lâ€™archive [archive.org](https://archive.org/details/aphorismesdhippo00hipp)  
- **Pages concernÃ©es** : 96 Ã  260, correspondant Ã  la traduction franÃ§aise principale  

### ğŸ”§ Ã‰tapes de prÃ©paration

1. **TÃ©lÃ©chargement et stockage local du PDF**
   - Le document a Ã©tÃ© tÃ©lÃ©chargÃ© depuis son adresse source et sauvegardÃ© localement dans le rÃ©pertoire `km/aphorismes_hippocrate.pdf`.
   - Ce tÃ©lÃ©chargement automatisÃ© facilite la reproductibilitÃ© du pipeline.

2. **Extraction du texte brut**
   - Ã€ lâ€™aide de la bibliothÃ¨que **PyMuPDF (fitz)**, chaque page pertinente a Ã©tÃ© analysÃ©e pour extraire son contenu textuel.
   - Les paragraphes ont Ã©tÃ© segmentÃ©s grÃ¢ce Ã  lâ€™analyse des espacements verticaux entre lignes, permettant dâ€™Ã©viter lâ€™intÃ©gration des notes de bas de page.

3. **Nettoyage du texte**
   - Suppression des tirets en fin de ligne pour fusionner les mots coupÃ©s.
   - Correction automatique des erreurs de numÃ©rotation (remplacement des virgules par des points aprÃ¨s les chiffres).
   - Normalisation des titres de sections (`PREMIÃˆRE SECTION` â†’ `SECTION.1`, etc.).

4. **Extraction structurÃ©e des aphorismes**
   - Chaque aphorisme a Ã©tÃ© identifiÃ© par son numÃ©ro (ex. `01`, `23`) et extrait sous forme dâ€™un objet JSON contenant :
     - NumÃ©ro de lâ€™aphorisme
     - Texte associÃ©
     - Page source
     - Section thÃ©matique
   - Gestion fine des cas oÃ¹ un aphorisme est coupÃ© sur deux pages consÃ©cututives.

5. **Segmentation adaptÃ©e au RAG (Chunking)**
   - Afin de rÃ©pondre aux contraintes techniques des modÃ¨les dâ€™embedding et de LLM :
     - Les aphorismes courts (< 450 caractÃ¨res) sont conservÃ©s tels quels.
     - Les aphorismes moyens (450â€“800 caractÃ¨res) sont dÃ©coupÃ©s en deux segments.
     - Les plus longs (> 800 caractÃ¨res) sont divisÃ©s en trois parties avec un lÃ©ger chevauchement.
   - Cette segmentation assure une bonne couverture contextuelle lors du retrieval.

6. **Format final pour le RAG**
   - Un document type inclut :
     - Un identifiant unique (`s1.aph_01.p100`)
     - Le texte segmentÃ©
     - Des mÃ©tadonnÃ©es prÃ©cises (section, page, source)
   - Une introduction contextuelle a Ã©galement Ã©tÃ© ajoutÃ©e pour enrichir les rÃ©ponses gÃ©nÃ©rÃ©es.

### âœ… RÃ©sultat final
Le corpus est dÃ©sormais prÃªt Ã  Ãªtre intÃ©grÃ© dans un moteur de recherche vectorielle (comme FAISS, Chroma ou Elasticsearch), suivi dâ€™une phase de gÃ©nÃ©ration assistÃ©e par un modÃ¨le de langage (LLM). Il constitue une base solide pour interprÃ©ter, analyser et dialoguer avec les *Aphorismes dâ€™Hippocrate* Ã  travers une approche moderne de traitement du langage naturel.

---

## ğŸ› ï¸ Configuration du systÃ¨me RAG Hippocratique

Le fichier `rag_config.yaml` centralise tous les paramÃ¨tres de configuration du systÃ¨me **HippocRAG**, permettant une gestion modulaire et flexible des diffÃ©rents composants : application web, moteur de recherche sÃ©mantique (RAG), modÃ¨le de langage (LLM) et rÃ¨gles de sÃ©curitÃ©.

---

### ğŸ–¥ï¸ Configuration de l'application Flask

| ParamÃ¨tre        | Valeur par dÃ©faut                   | Description |
|------------------|-------------------------------------|-------------|
| `name`           | `"HippocRAG"`                       | Nom de lâ€™application |
| `debug`          | `true`                              | Active le mode debug pour le dÃ©veloppement |
| `host`           | `"0.0.0.0"`                         | HÃ´te dâ€™Ã©coute (pour dÃ©ploiement externe) |
| `port`           | `5000`                              | Port dâ€™Ã©coute de lâ€™application |
| `secret_key`     | `"change_this_secret"`              | ClÃ© secrÃ¨te utilisÃ©e par Flask pour les sessions |
| `data_dir`       | `"data"`                            | RÃ©pertoire contenant les donnÃ©es textuelles |
| `cache_dir`      | `"cache"`                           | Dossier utilisÃ© pour le cache des rÃ©ponses gÃ©nÃ©rÃ©es |
| `question_cache_file` | `"questions_cache.json"`     | Fichier JSON stockant les rÃ©ponses dÃ©jÃ  traitÃ©es |

---

### ğŸ” Configuration du moteur RAG

| ParamÃ¨tre             | Valeur par dÃ©faut                                  | Description |
|-----------------------|----------------------------------------------------|-------------|
| `model.name`          | `"dangvantuan/sentence-camembert-large"`         | ModÃ¨le SentenceTransformer pour les embeddings |
| `normalize_embeddings`| `true`                                             | Normalisation des vecteurs avant indexation |
| `index.json_path`     | `"data/hippocrate_rag_data.json"`                | Chemin vers le corpus segmentÃ© |
| `faiss_path`          | `"hippocrate.index"`                             | Emplacement de lâ€™index FAISS prÃ©-entraÃ®nÃ© |
| `build_on_startup`    | `true`                                             | Reconstruit lâ€™index au dÃ©marrage si activÃ© |
| `top_k`               | `6`                                                | Nombre de documents rÃ©cupÃ©rÃ©s pour chaque requÃªte |

> ğŸ’¡ Le modÃ¨le `"sentence-camembert-large"` est particuliÃ¨rement adaptÃ© au franÃ§ais ancien et moderne, ce qui en fait un choix pertinent pour lâ€™analyse des *Aphorismes dâ€™Hippocrate*.

---

### ğŸ¤– Configuration du LLM (ModÃ¨le de GÃ©nÃ©ration)

| ParamÃ¨tre   | Valeur par dÃ©faut                          | Description |
|-------------|--------------------------------------------|-------------|
| `provider`  | `"ollama"`                                 | SystÃ¨me dâ€™exÃ©cution des modÃ¨les locaux |
| `endpoint`  | `"http://localhost:11434/api/generate"`   | API REST dâ€™Ollama pour gÃ©nÃ©rer des rÃ©ponses |
| `model`     | `"mistral"`                                | ModÃ¨le de langage utilisÃ© pour la gÃ©nÃ©ration |

> ğŸ“Œ Ce projet est conÃ§u pour fonctionner avec un LLM en local via [Ollama](https://ollama.com), mais peut Ãªtre adaptÃ© Ã  d'autres fournisseurs comme OpenAI, HuggingFace ou LlamaCPP.

---

### ğŸ” SÃ©curitÃ©

| ParamÃ¨tre           | Valeur                                                                 | Description |
|---------------------|------------------------------------------------------------------------|-------------|
| `allowed_tags`      | Liste de balises HTML autorisÃ©es : `<p>`, `<h4>`, `<ul>`, `<em>`, etc. | ContrÃ´le strict du format de sortie HTML gÃ©nÃ©rÃ© par le LLM |

Cette liste blanche empÃªche toute injection de code malveillant dans les rÃ©ponses HTML, notamment en interdisant les balises `<script>`, `<iframe>`, etc.

---

### âœ… Utilisation

Ce fichier YAML doit Ãªtre prÃ©sent Ã  la racine du projet ou dans un dossier `config/`. Il est chargÃ© automatiquement au dÃ©marrage de lâ€™application via `config_loader.py` et validÃ© grÃ¢ce Ã  un schÃ©ma Pydantic (`GlobalConfig`).

---

### ğŸ”„ AdaptabilitÃ©

La modularitÃ© de cette configuration permet :
- De changer facilement de modÃ¨le dâ€™embedding ou de LLM.
- Dâ€™ajouter des fournisseurs ou backends supplÃ©mentaires.
- De personnaliser les balises HTML autorisÃ©es selon le contexte dâ€™utilisation.

---

Ce fichier constitue donc une base solide pour configurer et dÃ©ployer rapidement un systÃ¨me RAG centrÃ© sur les textes mÃ©dicaux classiques, tout en garantissant sÃ©curitÃ©, performance et extensibilitÃ©.

---

## ğŸ§  ImplÃ©mentation du moteur RAG Hippocratique : rag/hippocrag.py

Ce module implÃ©mente un systÃ¨me **RAG (Retrieval-Augmented Generation)** basÃ© sur les *Aphorismes dâ€™Hippocrate*, utilisant une approche combinÃ©e de **recherche sÃ©mantique avec FAISS** et de **gÃ©nÃ©ration assistÃ©e par modÃ¨le de langage**. Il est conÃ§u pour rÃ©pondre Ã  des questions mÃ©dicales ou philosophiques en s'appuyant uniquement sur les textes historiques prÃ©parÃ©s au prÃ©alable.

### ğŸ”§ FonctionnalitÃ©s principales

- **Recherche sÃ©mantique** : encode les aphorismes avec un modÃ¨le de transformation en embeddings vectoriels (`SentenceTransformer`).
- **Indexation efficace** : utilise la bibliothÃ¨que **FAISS** pour stocker et interroger rapidement les vecteurs.
- **GÃ©nÃ©ration contextuelle** : appelle un **LLM externe** via une API REST pour formuler une rÃ©ponse Ã  partir des fragments pertinents trouvÃ©s.
- **Support de configuration** : tout est configurable via un objet `config`, permettant de changer facilement de modÃ¨le, d'index ou dâ€™endpoint LLM.

---

### ğŸ“¦ DÃ©pendances utilisÃ©es

```python
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np
import json
import os
import requests
```

---

### ğŸ—ï¸ Classe principale : `HippocRAG_FAISS`

#### Initialisation
Prend une configuration en entrÃ©e qui dÃ©finit :
- Le modÃ¨le dâ€™embedding (`model.name`)
- Si les embeddings doivent Ãªtre normalisÃ©s
- Chemins vers lâ€™index FAISS et le fichier JSON des documents
- ParamÃ¨tres du LLM (endpoint et modÃ¨le)

Si configurÃ©, il construit automatiquement lâ€™index Ã  lâ€™initialisation.

#### MÃ©thodes clÃ©s

| MÃ©thode | Description |
|--------|-------------|
| `build_index()` | Encode tous les textes du corpus et sauvegarde l'index FAISS |
| `load_index()` | Charge lâ€™index FAISS et les documents si pas dÃ©jÃ  chargÃ©s |
| `search(query)` | Recherche les `top_k` documents les plus proches de la requÃªte |
| `generate(question, passages)` | GÃ©nÃ¨re une rÃ©ponse HTML structurÃ©e Ã  partir des passages trouvÃ©s |

---

### ğŸ’¬ Exemple de prompt pour gÃ©nÃ©ration

La classe gÃ©nÃ¨re un prompt dÃ©taillÃ© pour le LLM, lui demandant de :
- RÃ©pondre en franÃ§ais
- Utiliser uniquement les balises HTML spÃ©cifiÃ©es
- Adopter un ton socratique et pÃ©dagogique
- Se baser exclusivement sur le contexte fourni

Cela garantit que les rÃ©ponses restent fidÃ¨les Ã  lâ€™esprit des *Aphorismes*.

---

### ğŸ“ Les fichiers en inputs

Le systÃ¨me s'appuit sur les fichiers suivants :

- `data/hippocrate_rag_data.json` : corpus segmentÃ© et prÃªt pour le RAG  
- `index/hippocrate.faiss` : index FAISS binaire prÃ©calculÃ©  

---

### âœ… Utilisation typique

```python
rag = HippocRAG_FAISS(config)
results = rag.search("Quel est le rÃ´le du rÃ©gime dans la santÃ© ?")
answer = rag.generate("Quel est le rÃ´le du rÃ©gime dans la santÃ© ?", results)
print(answer)
```
---

## ğŸŒ API et Interface Web pour le RAG Hippocratique

Ce module implÃ©mente une **application web lÃ©gÃ¨re** basÃ©e sur **Flask**, permettant dâ€™interfacer le systÃ¨me **RAG sur les Aphorismes dâ€™Hippocrate** via une interface utilisateur simple. Lâ€™objectif est de rendre accessible la recherche et lâ€™interprÃ©tation des textes mÃ©dicaux classiques Ã  travers un navigateur, tout en conservant un contrÃ´le strict sur la sÃ©curitÃ© et les performances.

---

### ğŸ”§ FonctionnalitÃ©s principales

- **Interface utilisateur HTML/Flask** : formulaire interactif pour poser des questions.
- **Gestion par thÃ¨mes** : liste de questions prÃ©chargÃ©es organisÃ©es thÃ©matiquement.
- **Cache de rÃ©ponses** : Ã©vite de recalculer les rÃ©ponses dÃ©jÃ  gÃ©nÃ©rÃ©es.
- **Nettoyage HTML** : protection contre injections XSS grÃ¢ce Ã  `bleach`.
- **API lÃ©gÃ¨re** : endpoint `/api/questions` pour charger dynamiquement des questions par thÃ¨me.
- **Configuration centralisÃ©e** : utilise un fichier YAML + schÃ©ma Pydantic (`GlobalConfig`) pour gÃ©rer tous les paramÃ¨tres.

---

### ğŸ“¦ DÃ©pendances utilisÃ©es

```python
from flask import Flask, render_template, request, jsonify, redirect, url_for
import yaml
import json
import os
import bleach
from datetime import datetime
from config_loader import load_config
from models.config_schema import GlobalConfig
from rag.hippocrag import HippocRAG_FAISS
```

---

### ğŸ—ï¸ Architecture globale

#### 1. **Initialisation**
- La configuration est chargÃ©e depuis un fichier YAML et validÃ©e avec Pydantic.
- Le moteur RAG (`HippocRAG_FAISS`) est instanciÃ© au dÃ©marrage.
- Les questions prÃ©dÃ©finies sont chargÃ©es depuis un fichier JSON.

#### 2. **Moteur de cache**
- Les rÃ©ponses gÃ©nÃ©rÃ©es sont stockÃ©es localement dans un fichier JSON.
- RÃ©duit les appels inutiles au LLM et amÃ©liore les temps de rÃ©ponse.

#### 3. **SÃ©curitÃ©**
- Utilisation de `bleach` pour nettoyer toute rÃ©ponse HTML gÃ©nÃ©rÃ©e par le LLM.
- Liste blanche des balises autorisÃ©es (configurable).

#### 4. **Routes principales**

| Route | MÃ©thode | Description |
|-------|---------|-------------|
| `/` | GET/POST | Page principale avec formulaire de question |
| `/api/questions` | GET | Retourne les questions associÃ©es Ã  un thÃ¨me |
| `/reset-cache` | POST | Permet de vider le cache des rÃ©ponses |

---

### ğŸ“ Fichiers en input

Le projet s'appuie sur les fichers suivants :

- **Fichiers de donnÃ©es** :
  - `data/hippocrates_questions.json` : questions prÃ©dÃ©finies organisÃ©es par thÃ¨me
- **Fichiers de configuration** :
  - `config/config.yaml` : paramÃ¨tres globaux
- **ModÃ¨les de donnÃ©es** :
  - `models/config_schema.py` : dÃ©finition du schÃ©ma de configuration
- **Templates Jinja2** :
  - `templates/index.html` : page dâ€™accueil interactive

---

### ğŸ’¬ Exemple de fonctionnement

Un utilisateur peut :
1. Choisir un thÃ¨me mÃ©dical (ex. "Prognostic", "Ã‰pidÃ©mies")
2. SÃ©lectionner ou formuler une question personnalisÃ©e
3. Obtenir une rÃ©ponse structurÃ©e en HTML, issue du RAG
4. Voir les fragments de texte ayant servi Ã  gÃ©nÃ©rer cette rÃ©ponse

---

### ğŸ”„ Perspectives dâ€™Ã©volution

- Ajout dâ€™un systÃ¨me de feedback utilisateur pour affiner les rÃ©ponses
- GÃ©nÃ©ration de fiches imprimables (PDF) des rÃ©ponses
- IntÃ©gration dâ€™une version historique des textes en grec ancien
- Support multilingue (anglais, grec moderne)
- Interface admin pour enrichir les thÃ¨mes et questions

---

### ğŸš€ DÃ©marrage rapide

Pour exÃ©cuter l'application :

```bash
python app.py
```

Puis accÃ©der Ã  lâ€™interface via : [http://localhost:5000](http://localhost:5000)

---

Ce module constitue une **couche applicative claire et modulaire**, permettant dâ€™exposer les capacitÃ©s du moteur RAG aux utilisateurs finaux, qu'ils soient chercheurs, enseignants ou Ã©tudiants en histoire de la mÃ©decine.

---
## ğŸ“¢ Contributions

Toute contribution visant Ã  enrichir :
- Le corpus (nouvelles traductions, annotations)
- Les questions prÃ©dÃ©finies
- La documentation pÃ©dagogique  
est la bienvenue !

---

## ğŸ“„ Licence

MIT License â€“ Voir le fichier [LICENSE](LICENSE)

---

## ğŸ§‘â€ğŸ’» Auteur

*micheldpd*
IngÃ©nieur ML passionnÃ© par lâ€™Histoire de la MÃ©decine
